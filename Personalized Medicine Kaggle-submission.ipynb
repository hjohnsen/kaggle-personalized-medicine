{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add:\n",
    "* lowering sentences seems to be helpful\n",
    "* averaging XGBoost and LR seems to help slightly\n",
    "* finding sentences for g + v separately is good, then use both\n",
    "* for cutoffs, use nEmpty instead of len(merged).\n",
    "* will use bigrams based on g (lower gene!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import _pickle as pickle\n",
    "import string\n",
    "import os\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hjohnsen/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Users/hjohnsen/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaking merged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('processedmerged.pkl'):\n",
    "    print(\"remaking merged\")\n",
    "    tvarsdf = pd.read_csv('training_variants', sep=\",\")\n",
    "    tvarsdf[\"split\"]=np.random.random([len(tvarsdf)])<0.8\n",
    "    ttextdf = pd.read_csv('training_text', sep=\"\\|\\|\")\n",
    "    ttextdf.rename(columns={'ID,Text': \"Text\"}, inplace = True)\n",
    "    ttextdf[\"ID\"]=ttextdf.index\n",
    "    merged = pd.merge(tvarsdf,ttextdf, how=\"inner\")\n",
    "    merged[\"Text\"]=merged[\"Text\"].str.lower()\n",
    "    merged[\"tokenized\"]=merged[\"Text\"].map(nltk.word_tokenize)    \n",
    "    merged[\"Gene\"]=merged[\"Gene\"].str.lower()\n",
    "#    with open(\"tokenized.pkl\",'wb') as f:\n",
    "#        pickle.dump(merged, f)\n",
    "else:\n",
    "    merged=pickle.load(open('processedmerged.pkl','rb'))\n",
    "    merged=merged[[\"ID\",\"Gene\",\"Text\",\"Variation\", \"Class\", \"tokenized\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import time\n",
    "if not os.path.exists('tokenized.pkl'):\n",
    "    tvarsdf = pd.read_csv('training_variants', sep=\",\")\n",
    "    tvarsdf[\"split\"]=np.random.random([len(tvarsdf)])<0.8\n",
    "    ttextdf = pd.read_csv('training_text', sep=\"\\|\\|\")\n",
    "    ttextdf.rename(columns={'ID,Text': \"Text\"}, inplace = True)\n",
    "    ttextdf[\"ID\"]=ttextdf.index\n",
    "    merged = pd.merge(tvarsdf,ttextdf, how=\"inner\")\n",
    "    merged[\"tokenized\"]=merged[\"Text\"].map(nltk.word_tokenize)\n",
    "    with open(\"tokenized.pkl\",'wb') as f:\n",
    "        pickle.dump(merged, f)\n",
    "else:\n",
    "    while True:\n",
    "        try:\n",
    "            merged=pickle.load(open('tokenized.pkl','rb'))\n",
    "            merged=merged[[\"ID\",\"Gene\",\"Text\",\"Variation\", \"Class\", \"tokenized\"]]\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueGenes = merged[\"Gene\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_of_words_features_filtered(words):\n",
    "    bag = {}\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "    for word in words:\n",
    "        if not word in useless_words:\n",
    "            bag[word]=1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_of_genes(words):\n",
    "    bag={}\n",
    "    for word in words:\n",
    "        if word.upper() in uniqueGenes:\n",
    "            bag[word.upper()]=1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = [\"fusion\", \"del\", \"dup\", \"ins\", \"trunc\", \"splice\", \"\\*\"]\n",
    "def findMutTypes(types, df):\n",
    "    for i in types:\n",
    "        df[\"is\"+i] = df[\"Variation\"].str.lower().str.contains(i).astype(int)\n",
    "\n",
    "    df[\"mutType\"]=list(zip(df[\"isfusion\"], \n",
    "                           df[\"isdel\"], \n",
    "                           df[\"isdup\"], \n",
    "                           df[\"isins\"], \n",
    "                           df[\"istrunc\"], \n",
    "                           df[\"issplice\"], \n",
    "                           df[\"is\\*\"]))\n",
    "    df[\"mutType\"]=df[\"mutType\"].map(list)\n",
    "\n",
    "    for i in types:\n",
    "        del df[\"is\"+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getvSentences(gene, variation, text):\n",
    "    sentences = \"\"\n",
    "    splitText = text.split(\".\")\n",
    "    for sentence in splitText:\n",
    "        if variation.lower() in sentence.lower():\n",
    "            sentences += sentence\n",
    "    return sentences.lower()\n",
    "    \n",
    "def applyvGetSentences(row):\n",
    "    gene = row[\"Gene\"]\n",
    "    variation = row[\"Variation\"]\n",
    "    text = row[\"Text\"]\n",
    "    return getvSentences(gene, variation, text)\n",
    "\n",
    "def getgSentences(gene, variation, text):\n",
    "    variation = gene\n",
    "    sentences = \"\"\n",
    "    splitText = text.split(\".\")\n",
    "    for sentence in splitText:\n",
    "        if variation.lower() in sentence.lower():\n",
    "            sentences += sentence\n",
    "    return sentences.lower()\n",
    "    \n",
    "def applygGetSentences(row):\n",
    "    gene = row[\"Gene\"]\n",
    "    variation = row[\"Variation\"]\n",
    "    text = row[\"Text\"]\n",
    "    return getgSentences(gene, variation, text)\n",
    "\n",
    "def find_bigrams(input_sentence):\n",
    "    input_list = input_sentence.split()\n",
    "    return list(zip(input_list, input_list[1:]))\n",
    "\n",
    "\n",
    "def getabridgedwords(df):\n",
    "    wordcounts = {}\n",
    "    for i in df[\"tokenized\"]:\n",
    "        words = set(i)\n",
    "        for word in words:\n",
    "            wordcounts[word] = wordcounts.get(word,0)+1\n",
    "    sortedwords = sorted(wordcounts.items(), key=lambda c: c[1], reverse=True)\n",
    "    abridgedsorted = {}\n",
    "    for (k,v) in sortedwords:\n",
    "        if v< len(merged)*.9 and v>len(merged)*.1:\n",
    "            abridgedsorted[k]=v\n",
    "    return abridgedsorted\n",
    "\n",
    "\n",
    "def getabridgedsentencewords(array):\n",
    "    nEmpty = 0\n",
    "    wordcounts = {}\n",
    "    for i in array:\n",
    "        if len(i)>0:        \n",
    "            nEmpty+=1\n",
    "        words = set(i)\n",
    "        for word in words:\n",
    "            wordcounts[word] = wordcounts.get(word,0)+1\n",
    "    sortedwords = sorted(wordcounts.items(), key=lambda c: c[1], reverse=True)\n",
    "    abridgedsentencewords = {}\n",
    "    for (k,v) in sortedwords:\n",
    "        if v< nEmpty*.9 and v>nEmpty*.1:\n",
    "            abridgedsentencewords[k]=v\n",
    "    return abridgedsentencewords\n",
    "\n",
    "\n",
    "\n",
    "def getabridgedbigrams(df):\n",
    "    flat_list = [item for sublist in df[\"bigrams\"].tolist() for item in set(sublist)]\n",
    "    bigs = {}\n",
    "    for i in flat_list:\n",
    "        bigs[i] = bigs.get(i,0)+1\n",
    "    sortedbgs=sorted(bigs.items(), key=lambda c: c[1], reverse=True)\n",
    "    abridgedsortedbgs = {}\n",
    "    for (k,v) in sortedbgs:\n",
    "        if v< len(df)*.5 and v>59:\n",
    "            abridgedsortedbgs[k]=v\n",
    "    return abridgedsortedbgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeAllTheBags(df):\n",
    "    df[\"wordbag\"]=df[\"tokenized\"].map(build_bag_of_words_features_filtered)\n",
    "    print(\"wordbag made\")\n",
    "    df[\"genebag\"]=df[\"tokenized\"].map(build_bag_of_genes)\n",
    "    print(\"genebag made\")\n",
    "    df[\"gSentences\"] = df.apply(applygGetSentences, axis = 1)\n",
    "    df[\"vSentences\"] = df.apply(applyvGetSentences, axis = 1)\n",
    "    print(\"sentences made\")\n",
    "    df[\"tokenizedgSentences\"]=df[\"gSentences\"].map(nltk.word_tokenize)\n",
    "    df[\"tokenizedvSentences\"]=df[\"vSentences\"].map(nltk.word_tokenize)\n",
    "    print(\"sentences tokenized\")\n",
    "    df[\"sentencegWordBag\"]=df[\"tokenizedgSentences\"].map(build_bag_of_words_features_filtered)\n",
    "    df[\"sentencevWordBag\"]=df[\"tokenizedvSentences\"].map(build_bag_of_words_features_filtered)\n",
    "    print(\"sentence wordbag made\")\n",
    "    df[\"bigrams\"]=df[\"gSentences\"].map(find_bigrams)\n",
    "    print(\"bigrams made\")\n",
    "    \n",
    "def makeAllTheFeatures(df):\n",
    "    df[\"genesmentioned\"]=df[\"genebag\"].map(lambda b: [int(gene in b) for gene in uniqueGenes])\n",
    "    print(\"genebag feature made\")\n",
    "    df[\"geneofinterest\"]=df[\"Gene\"].map(lambda b: [int(gene == b) for gene in uniqueGenes])\n",
    "    print(\"goi made\")\n",
    "    df[\"wordfeatures\"]=df[\"wordbag\"].map(lambda b: [int(word in b.keys()) for word in abridgedsorted.keys()])\n",
    "    print(\"wordfeatures made\")\n",
    "    findMutTypes(types, df)\n",
    "    print(\"muttype features made\")\n",
    "    df[\"sentencegWordFeatures\"]=df[\"sentencegWordBag\"].map(lambda b: [int(word in b.keys()) for word in abridgedsentencegwords.keys()])\n",
    "    df[\"sentencevWordFeatures\"]=df[\"sentencevWordBag\"].map(lambda b: [int(word in b.keys()) for word in abridgedsentencevwords.keys()])\n",
    "    print(\"sentence word features made\")\n",
    "    df[\"bigramfeatures\"]=df[\"bigrams\"].map(lambda b: [int(word in b) for word in abridgedsortedbgs.keys()])\n",
    "    print(\"bigram features made\")\n",
    "    \n",
    "    df[\"all\"]=df[\"wordfeatures\"]+df[\"genesmentioned\"]+df[\"geneofinterest\"]+df[\"mutType\"]+df[\"sentencegWordFeatures\"]+df[\"sentencevWordFeatures\"]+df[\"bigramfeatures\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged[\"all\"]=merged[\"wordfeatures\"]+merged[\"genesmentioned\"]+merged[\"geneofinterest\"]+merged[\"mutType\"]+merged[\"sentencegWordFeatures\"]+merged[\"sentencevWordFeatures\"]+merged[\"bigramfeatures\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordbag made\n",
      "genebag made\n",
      "sentences made\n",
      "sentences tokenized\n",
      "sentence wordbag made\n",
      "bigrams made\n",
      "genebag feature made\n",
      "goi made\n",
      "wordfeatures made\n",
      "muttype features made\n",
      "sentence word features made\n",
      "bigram features made\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sentenceWordFeatures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentenceWordFeatures'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-63bd8cf1f909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mabridgedsortedbgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetabridgedbigrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmakeAllTheFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-a3b0ed2bb966>\u001b[0m in \u001b[0;36mmakeAllTheFeatures\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bigram features made\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wordfeatures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genesmentioned\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geneofinterest\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mutType\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentenceWordFeatures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bigramfeatures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sentenceWordFeatures'"
     ]
    }
   ],
   "source": [
    "makeAllTheBags(merged)\n",
    "\n",
    "abridgedsorted=getabridgedwords(merged)\n",
    "abridgedsentencegwords=getabridgedsentencewords(merged[\"sentencegWordBag\"])\n",
    "abridgedsentencevwords=getabridgedsentencewords(merged[\"sentencevWordBag\"])\n",
    "abridgedsortedbgs=getabridgedbigrams(merged)\n",
    "\n",
    "makeAllTheFeatures(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaking testmerged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('tokenizedtest.pkl'):\n",
    "    print(\"remaking testmerged\")\n",
    "    testvarsdf = pd.read_csv('stage2_test_variants.csv', sep=\",\")\n",
    "    testtextdf = pd.read_csv('stage2_test_text.csv', sep=\"\\|\\|\")\n",
    "    testtextdf.rename(columns={'ID,Text': \"Text\"}, inplace = True)\n",
    "    testtextdf[\"ID\"]=testtextdf.index\n",
    "    testmerged = pd.merge(testvarsdf,testtextdf, how=\"inner\")\n",
    "    testmerged[\"Text\"]=testmerged[\"Text\"].str.lower()    \n",
    "    testmerged[\"tokenized\"]=testmerged[\"Text\"].map(nltk.word_tokenize)\n",
    "    testmerged[\"Gene\"]=testmerged[\"Gene\"].str.lower()    \n",
    "#    with open(\"tokenizedtest.pkl\",'wb') as f:\n",
    "#        pickle.dump(testmerged, f)\n",
    "else:\n",
    "    testmerged=pickle.load(open('tokenizedtest.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordbag made\n",
      "genebag made\n",
      "sentences made\n",
      "sentences tokenized\n",
      "sentence wordbag made\n",
      "bigrams made\n",
      "genebag feature made\n",
      "goi made\n",
      "wordfeatures made\n",
      "muttype features made\n",
      "sentence word features made\n",
      "bigram features made\n"
     ]
    }
   ],
   "source": [
    "makeAllTheBags(testmerged)\n",
    "makeAllTheFeatures(testmerged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = merged\n",
    "test = testmerged\n",
    "X_train = training[\"all\"].tolist()\n",
    "y_train = training[\"Class\"].tolist()\n",
    "X_test=test[\"all\"].tolist()\n",
    "\n",
    "lr = LogisticRegression( solver = \"lbfgs\",\n",
    "                                multi_class=\"multinomial\",\n",
    "                                penalty='l2',\n",
    "                                C=1e-2,\n",
    "                                fit_intercept=True\n",
    "                                )\n",
    "lr.fit(X_train, y_train)\n",
    "y_predlr = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open(\"submission.csv\", \"w\") as out:\n",
    "    out.write(\"ID,class1,class2,class3,class4,class5,class6,class7,class8,class9\\n\")\n",
    "    for i,j in enumerate(y_pred):\n",
    "        out.write(str(i+1)+\",\")\n",
    "        out.write(\",\".join(map(str, j)))\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(eval_metric=\"mlogloss\", max_depth=6)\n",
    "training = merged\n",
    "test = testmerged\n",
    "X_train = np.array(training[\"all\"].tolist())\n",
    "y_train = np.array(training[\"Class\"].tolist())\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test=test[\"all\"].tolist()\n",
    "y_predxgb = model.predict_proba(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = ((y_predlr)+(y_predxgb))/2\n",
    "\n",
    "with open(\"xgbsubmission.csv\", \"w\") as out:\n",
    "    out.write(\"ID,class1,class2,class3,class4,class5,class6,class7,class8,class9\\n\")\n",
    "    for i,j in enumerate(y_pred):\n",
    "        out.write(str(i+1)+\",\")\n",
    "        out.write(\",\".join(map(str, j)))\n",
    "        out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testmerged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testvarsdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testtextdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testmerged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pyplot\n",
    "# plot\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordfeatures 0 to 3578\n",
      "genesmentioned 3578 to 3842\n",
      "geneofinterest 3842 to 4106\n",
      "mutType 4106 to 4113\n",
      "sentencegWordFeatures 4113 to 5930\n",
      "bigramfeatures 5930 to 23668\n"
     ]
    }
   ],
   "source": [
    "#df[\"wordfeatures\"]+df[\"genesmentioned\"]+df[\"geneofinterest\"]+df[\"mutType\"]+df[\"sentenceWordFeatures\"]+df[\"bigramfeatures\"]\n",
    "wf = len(merged[\"wordfeatures\"][0])\n",
    "gm = len(merged[\"genesmentioned\"][0])\n",
    "gi = len(merged[\"geneofinterest\"][0])\n",
    "mt = len(merged[\"mutType\"][0])\n",
    "swf= len(merged[\"sentencegWordFeatures\"][0])+len(merged[\"sentencevWordFeatures\"][0])\n",
    "bgf= len(merged[\"bigramfeatures\"][0])\n",
    "\n",
    "print(\"wordfeatures \" + \"0\" + \" to \" + str(wf))\n",
    "print(\"genesmentioned \" + str(wf) + \" to \" + str(wf+gm))\n",
    "print(\"geneofinterest \" + str(wf+gm) + \" to \" + str(wf+gm+gi))\n",
    "print(\"mutType \" + str(wf+gm+gi) + \" to \" + str(wf+gm+gi+mt))\n",
    "print(\"sentencegWordFeatures \" + str(wf+gm+gi+mt) + \" to \" + str(wf+gm+gi+mt+swf))\n",
    "print(\"bigramfeatures \" + str(wf+gm+gi+mt+swf) + \" to \" + str(wf+gm+gi+mt+swf+bgf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyplot.figure(figsize=(10,5))\n",
    "pyplot.axvline(3862)\n",
    "pyplot.axvline(4131)\n",
    "pyplot.axvline(4400)\n",
    "pyplot.axvline(4407)\n",
    "pyplot.axvline(5013)\n",
    "pyplot.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"processedmerged.pkl\",'wb') as f:\n",
    "    pickle.dump(merged, f)\n",
    "with open(\"processedtestmerged.pkl\",'wb') as f:\n",
    "    pickle.dump(testmerged, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23668\n"
     ]
    }
   ],
   "source": [
    "print(len(merged[\"all\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged[\"nobgs\"]=merged[\"wordfeatures\"]+merged[\"genesmentioned\"]+merged[\"geneofinterest\"]+merged[\"mutType\"]+merged[\"sentencegWordFeatures\"]+merged[\"sentencevWordFeatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged[\"split\"]=np.random.random([len(merged)])<0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistictester(df, X, Y, C=1e-2):\n",
    "    training = df[df[\"split\"]]\n",
    "    test = df[df[\"split\"]==False]\n",
    "    X_train = training[X].tolist()\n",
    "    y_train = training[Y].tolist()\n",
    "    X_test=test[X].tolist()\n",
    "\n",
    "    lr = LogisticRegression( solver = \"lbfgs\",\n",
    "                                multi_class=\"multinomial\",\n",
    "                                penalty='l2',\n",
    "                                C=C,\n",
    "                                fit_intercept=True\n",
    "                                )\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict_proba(X_test) \n",
    "    \n",
    "    ls = []\n",
    "    for i in range(len(y_pred)):\n",
    "        c = test.iloc[i][Y]\n",
    "        prob = y_pred[i][c-1]\n",
    "        ls.append(-np.log(prob+1e-6))\n",
    "\n",
    "    print(\"Accuracy on test set:\")\n",
    "    print(np.mean(ls))\n",
    "\n",
    "    ytrain_pred = lr.predict_proba(X_train)\n",
    "    ls = []\n",
    "    for i in range(len(ytrain_pred)):\n",
    "        c = training.iloc[i][\"Class\"]\n",
    "        prob = ytrain_pred[i][c-1]\n",
    "        ls.append(-np.log(prob+1e-6))\n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(np.mean(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:\n",
      "0.920736077104\n",
      "Accuracy on training set:\n",
      "0.335322950712\n",
      "Accuracy on test set:\n",
      "0.919453301164\n",
      "Accuracy on training set:\n",
      "0.388750127138\n"
     ]
    }
   ],
   "source": [
    "logistictester(merged, \"all\", \"Class\")\n",
    "logistictester(merged, \"nobgs\", \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del merged[\"bigrams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del testmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "abridged\n",
      "features found\n"
     ]
    }
   ],
   "source": [
    "merged[\"bigrams\"]=merged[\"vSentences\"].map(find_bigrams)\n",
    "print(\"found\")\n",
    "abridgedsortedbgs=getabridgedbigrams(merged)\n",
    "print(\"abridged\")\n",
    "merged[\"bigramfeatures\"]=merged[\"bigrams\"].map(lambda b: [int(word in b) for word in abridgedsortedbgs.keys()])\n",
    "print(\"features found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged[\"plusvbgs\"]= merged[\"nobgs\"]+merged[\"bigramfeatures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:\n",
      "0.914128765578\n",
      "Accuracy on training set:\n",
      "0.371784775649\n"
     ]
    }
   ],
   "source": [
    "logistictester(merged, \"plusvbgs\", \"Class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23668\n",
      "981\n",
      "6911\n"
     ]
    }
   ],
   "source": [
    "print(len(merged[\"all\"][0]))\n",
    "print(len(merged[\"bigramfeatures\"][0]))\n",
    "print(len(merged[\"plusvbgs\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs=pd.read_csv(\"xgbsubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.057553</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.792881</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.002194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.944951</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.034696</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.010579</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.059542</td>\n",
       "      <td>0.244398</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>0.080165</td>\n",
       "      <td>0.535708</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.123668</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.151940</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.038985</td>\n",
       "      <td>0.531747</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.004765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.042695</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.874700</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    class1    class2    class3    class4    class5    class6    class7  \\\n",
       "0   1  0.057553  0.023231  0.005634  0.792881  0.013617  0.073030  0.030131   \n",
       "1   2  0.944951  0.002815  0.001411  0.034696  0.002216  0.002596  0.010579   \n",
       "2   3  0.059542  0.244398  0.004076  0.055069  0.013307  0.080165  0.535708   \n",
       "3   4  0.123668  0.130612  0.003017  0.151940  0.005809  0.038985  0.531747   \n",
       "4   5  0.009415  0.043537  0.005621  0.042695  0.015561  0.005647  0.874700   \n",
       "\n",
       "     class8    class9  \n",
       "0  0.001729  0.002194  \n",
       "1  0.000393  0.000343  \n",
       "2  0.005366  0.002369  \n",
       "3  0.009457  0.004765  \n",
       "4  0.001110  0.001713  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.99577381837216"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[\"class1\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in subs.columns[1:]:\n",
    "    su=subs[col].sum()\n",
    "    subs[col]=subs[col]/su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    class1    class2    class3    class4    class5    class6    class7  \\\n",
       "0   1  0.000333  0.000133  0.000467  0.004561  0.000373  0.001215  0.000088   \n",
       "1   2  0.005462  0.000016  0.000117  0.000200  0.000061  0.000043  0.000031   \n",
       "2   3  0.000344  0.001404  0.000338  0.000317  0.000364  0.001334  0.001566   \n",
       "3   4  0.000715  0.000750  0.000250  0.000874  0.000159  0.000649  0.001555   \n",
       "4   5  0.000054  0.000250  0.000466  0.000246  0.000426  0.000094  0.002558   \n",
       "\n",
       "     class8    class9  \n",
       "0  0.000290  0.000261  \n",
       "1  0.000066  0.000041  \n",
       "2  0.000901  0.000282  \n",
       "3  0.001588  0.000567  \n",
       "4  0.000186  0.000204  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs.to_csv(\"latesub.csv\", inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[\"class1\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>9.860000e+02</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>493.500000</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>1.014199e-03</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>284.777984</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>8.694272e-04</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.007955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8.023569e-07</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>247.250000</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1.793319e-04</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>493.500000</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>8.398229e-04</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>739.750000</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>1.623307e-03</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>986.000000</td>\n",
       "      <td>0.005616</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.068812</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>2.906599e-03</td>\n",
       "      <td>0.120984</td>\n",
       "      <td>0.116505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      class1      class2      class3      class4      class5  \\\n",
       "count  986.000000  986.000000  986.000000  986.000000  986.000000  986.000000   \n",
       "mean   493.500000    0.001014    0.001014    0.001014    0.001014    0.001014   \n",
       "std    284.777984    0.001365    0.001145    0.005117    0.001301    0.003076   \n",
       "min      1.000000    0.000002    0.000002    0.000013    0.000002    0.000013   \n",
       "25%    247.250000    0.000153    0.000164    0.000166    0.000135    0.000164   \n",
       "50%    493.500000    0.000477    0.000661    0.000299    0.000474    0.000288   \n",
       "75%    739.750000    0.001142    0.001398    0.000486    0.001472    0.000597   \n",
       "max    986.000000    0.005616    0.005625    0.068812    0.005686    0.025474   \n",
       "\n",
       "           class6        class7      class8      class9  \n",
       "count  986.000000  9.860000e+02  986.000000  986.000000  \n",
       "mean     0.001014  1.014199e-03    0.001014    0.001014  \n",
       "std      0.002098  8.694272e-04    0.005278    0.007955  \n",
       "min      0.000005  8.023569e-07    0.000014    0.000009  \n",
       "25%      0.000167  1.793319e-04    0.000268    0.000132  \n",
       "50%      0.000441  8.398229e-04    0.000518    0.000235  \n",
       "75%      0.000978  1.623307e-03    0.000894    0.000365  \n",
       "max      0.016216  2.906599e-03    0.120984    0.116505  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
